{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8784c58-b0ab-42f2-9b3d-09f976adb678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Employees', 'Departments']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'D:\\\\Data Science\\\\Datasets\\\\payroll_dataset.xlsx'\n",
    "xls = pd.ExcelFile('D:\\\\Data Science\\\\Datasets\\\\payroll_dataset.xlsx')\n",
    "\n",
    "# Display sheet names to understand the structure of the Excel file\n",
    "sheet_names = xls.sheet_names\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a439de8-320e-41c5-98f0-4d06f708fa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID        Name DepartmentID  Salary    HireDate     Location\n",
      "0           1  Employee 1         D001    6000  2020-01-31     New York\n",
      "1           2  Employee 2         D002    6100  2020-02-29  Los Angeles\n",
      "2           3  Employee 3         D003    6200  2020-03-31      Chicago\n",
      "3           4  Employee 4         D004    6300  2020-04-30      Houston\n",
      "4           5  Employee 5         D001    6400  2020-05-31     New York\n",
      "  DepartmentID DepartmentName\n",
      "0         D001             IT\n",
      "1         D002             HR\n",
      "2         D003        Finance\n",
      "3         D004      Marketing\n"
     ]
    }
   ],
   "source": [
    "# Load the data from each sheet into a DataFrame\n",
    "employees_df = pd.read_excel(xls, sheet_name='Employees')\n",
    "departments_df = pd.read_excel(xls, sheet_name='Departments')\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(employees_df.head())\n",
    "print(departments_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27322a34-aa95-4cb6-9f5c-1a78ec067402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID        Name DepartmentID  Salary    HireDate     Location  \\\n",
      "0           1  Employee 1         D001    6000  2020-01-31     New York   \n",
      "1           2  Employee 2         D002    6100  2020-02-29  Los Angeles   \n",
      "2           3  Employee 3         D003    6200  2020-03-31      Chicago   \n",
      "3           4  Employee 4         D004    6300  2020-04-30      Houston   \n",
      "4           5  Employee 5         D001    6400  2020-05-31     New York   \n",
      "\n",
      "  DepartmentName  \n",
      "0             IT  \n",
      "1             HR  \n",
      "2        Finance  \n",
      "3      Marketing  \n",
      "4             IT  \n"
     ]
    }
   ],
   "source": [
    "# Merge the Employees and Departments DataFrames on the DepartmentID column\n",
    "merged_df = pd.merge(employees_df, departments_df, on='DepartmentID')\n",
    "\n",
    "# Display the first 5 rows of the merged dataset\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c6e232-8097-4aec-bba7-05bc686a7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Records:\n",
      "Empty DataFrame\n",
      "Columns: [EmployeeID, Name, DepartmentID, Salary, HireDate, Location, DepartmentName]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the merged dataset\n",
    "duplicates = merged_df[merged_df.duplicated()]\n",
    "print(\"Duplicate Records:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd7fee1-88b6-40aa-8f8d-7085d5c66f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Records after Removal:\n",
      "Empty DataFrame\n",
      "Columns: [EmployeeID, Name, DepartmentID, Salary, HireDate, Location, DepartmentName]\n",
      "Index: []\n",
      "   EmployeeID        Name DepartmentID  Salary    HireDate     Location  \\\n",
      "0           1  Employee 1         D001    6000  2020-01-31     New York   \n",
      "1           2  Employee 2         D002    6100  2020-02-29  Los Angeles   \n",
      "2           3  Employee 3         D003    6200  2020-03-31      Chicago   \n",
      "3           4  Employee 4         D004    6300  2020-04-30      Houston   \n",
      "4           5  Employee 5         D001    6400  2020-05-31     New York   \n",
      "\n",
      "  DepartmentName  \n",
      "0             IT  \n",
      "1             HR  \n",
      "2        Finance  \n",
      "3      Marketing  \n",
      "4             IT  \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate records from the merged dataset\n",
    "merged_df_no_duplicates = merged_df.drop_duplicates()\n",
    "\n",
    "# Check for duplicates in the cleaned dataset\n",
    "cleaned_duplicates = merged_df_no_duplicates[merged_df_no_duplicates.duplicated()]\n",
    "print(\"Duplicate Records after Removal:\")\n",
    "print(cleaned_duplicates)\n",
    "\n",
    "# Display the first 5 rows of the dataset after removing duplicates\n",
    "print(merged_df_no_duplicates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53647295-529e-412f-8910-028b55fec8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 8475.0, Q3: 13425.0, IQR: 4950.0\n",
      "Lower Bound: 1050.0, Upper Bound: 20850.0\n",
      "   EmployeeID        Name DepartmentID  Salary    HireDate     Location  \\\n",
      "0           1  Employee 1         D001    6000  2020-01-31     New York   \n",
      "1           2  Employee 2         D002    6100  2020-02-29  Los Angeles   \n",
      "2           3  Employee 3         D003    6200  2020-03-31      Chicago   \n",
      "3           4  Employee 4         D004    6300  2020-04-30      Houston   \n",
      "4           5  Employee 5         D001    6400  2020-05-31     New York   \n",
      "\n",
      "  DepartmentName  \n",
      "0             IT  \n",
      "1             HR  \n",
      "2        Finance  \n",
      "3      Marketing  \n",
      "4             IT  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the IQR for the Salary column\n",
    "Q1 = merged_df_no_duplicates['Salary'].quantile(0.25)\n",
    "Q3 = merged_df_no_duplicates['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Print the calculated IQR values\n",
    "print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
    "\n",
    "# Define the bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Print the bounds for outliers\n",
    "print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "\n",
    "# Filter out outliers\n",
    "filtered_df = merged_df_no_duplicates[(merged_df_no_duplicates['Salary'] >= lower_bound) & (merged_df_no_duplicates['Salary'] <= upper_bound)]\n",
    "\n",
    "# Display the first 5 rows of the dataset after handling outliers\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b3be64-8163-41ef-8a31-197c1413ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID        Name DepartmentID  Salary    HireDate     Location  \\\n",
      "0           1  Employee 1         D001    6000  2020-01-31     New York   \n",
      "1           2  Employee 2         D002    6100  2020-02-29  Los Angeles   \n",
      "2           3  Employee 3         D003    6200  2020-03-31      Chicago   \n",
      "3           4  Employee 4         D004    6300  2020-04-30      Houston   \n",
      "4           5  Employee 5         D001    6400  2020-05-31     New York   \n",
      "\n",
      "  DepartmentName  Normalized_Salary  \n",
      "0             IT           0.000000  \n",
      "1             HR           0.010101  \n",
      "2        Finance           0.020202  \n",
      "3      Marketing           0.030303  \n",
      "4             IT           0.040404  \n"
     ]
    }
   ],
   "source": [
    "# Perform Min-Max normalization on the Salary column\n",
    "min_salary = filtered_df['Salary'].min()\n",
    "max_salary = filtered_df['Salary'].max()\n",
    "\n",
    "filtered_df['Normalized_Salary'] = (filtered_df['Salary'] - min_salary) / (max_salary - min_salary)\n",
    "\n",
    "# Display the first 5 rows of the dataset after normalization\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8911e0d3-cb70-4dfe-b93f-82c949d93aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID        Name DepartmentID  Salary    HireDate DepartmentName  \\\n",
      "0           1  Employee 1         D001    6000  2020-01-31             IT   \n",
      "1           2  Employee 2         D002    6100  2020-02-29             HR   \n",
      "2           3  Employee 3         D003    6200  2020-03-31        Finance   \n",
      "3           4  Employee 4         D004    6300  2020-04-30      Marketing   \n",
      "4           5  Employee 5         D001    6400  2020-05-31             IT   \n",
      "\n",
      "   Normalized_Salary  Location_Chicago  Location_Houston  \\\n",
      "0           0.000000             False             False   \n",
      "1           0.010101             False             False   \n",
      "2           0.020202              True             False   \n",
      "3           0.030303             False              True   \n",
      "4           0.040404             False             False   \n",
      "\n",
      "   Location_Los Angeles  Location_New York  \n",
      "0                 False               True  \n",
      "1                  True              False  \n",
      "2                 False              False  \n",
      "3                 False              False  \n",
      "4                 False               True  \n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding to the Location column\n",
    "encoded_df = pd.get_dummies(filtered_df, columns=['Location'])\n",
    "\n",
    "# Display the first 5 rows of the updated dataset\n",
    "print(encoded_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
